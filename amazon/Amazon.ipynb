{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "input: dataframe with a column named \"book_url\"\n",
        "do: scrape every row\n",
        "return: dataframe with \"rank\" and original price of the url but without the book name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UWq5fRzqOU1v"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import time\n",
        "import random\n",
        "import requests\n",
        "import os\n",
        "import pandas as pd\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime, timedelta\n",
        "import re\n",
        "from selenium import webdriver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def set_up_driver(headless=True):\n",
        "    chrome_options = Options()\n",
        "    chrome_options.add_argument(\"--window-size=1920,1080\")\n",
        "    if headless:\n",
        "        chrome_options.add_argument(\"--headless\")\n",
        "    chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\")\n",
        "    return webdriver.Chrome(service=Service(r\"C:\\Users\\USER\\OneDrive\\桌面\\C2L2\\chromedriver.exe\"), options=chrome_options)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bGxB01c3PxtI"
      },
      "outputs": [],
      "source": [
        "def crawler(url):\n",
        "    driver = set_up_driver()\n",
        "    driver.get(url)\n",
        "    driver.refresh()\n",
        "\n",
        "    i = 0\n",
        "    while True:\n",
        "\n",
        "        time.sleep(1)\n",
        "        driver.refresh()\n",
        "\n",
        "        # 隨機選取秒數\n",
        "        time.sleep(1)\n",
        "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
        "        i = i + 1\n",
        "        print(i, end=\" \")\n",
        "        refuse_request = [\n",
        "            \"Request was throttled. Please wait a moment and refresh the page\",\n",
        "            \"      503 - Service Unavailable Error\",\n",
        "            \"Amazon.comEnter the characters you see belowSorry, we just need to make sure you're not a robot. For best results, please make sure your browser is accepting cookies.Type the characters you see in this image:Try different imageContinue shoppingConditions of UsePrivacy Policy          © 1996-2014, Amazon.com, Inc. or its affiliates          \",\n",
        "        ]\n",
        "        if soup.text.replace(\"\\n\", \"\") in refuse_request:\n",
        "            driver.close()\n",
        "            time.sleep(1 * i)\n",
        "\n",
        "            driver = set_up_driver()\n",
        "            driver.get(url)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    driver.close()\n",
        "    return soup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVtEhf5fo1dp"
      },
      "source": [
        "# 爬內容"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Jvgy0HQno6oU"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"sampled_book_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "hqOaMew3qP7g"
      },
      "outputs": [],
      "source": [
        "all_rank, other_info, origin_price = [], [], []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFbYHPfCqGRH",
        "outputId": "4a464cdd-deed-4194-e046-4bf7bede5e2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 1 1 1 1 1 1 1 1 1 1 1 1 1 "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function Service.__del__ at 0x000001AB4CDFECB0>\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\USER\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\common\\service.py\", line 185, in __del__\n",
            "    self.stop()\n",
            "  File \"c:\\Users\\USER\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\common\\service.py\", line 146, in stop\n",
            "    self.send_remote_shutdown_command()\n",
            "  File \"c:\\Users\\USER\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\common\\service.py\", line 131, in send_remote_shutdown_command\n",
            "    if not self.is_connectable():\n",
            "  File \"c:\\Users\\USER\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\common\\service.py\", line 120, in is_connectable\n",
            "    return utils.is_connectable(self.port)\n",
            "  File \"c:\\Users\\USER\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\common\\utils.py\", line 101, in is_connectable\n",
            "    socket_ = socket.create_connection((host, port), 1)\n",
            "  File \"c:\\Users\\USER\\anaconda3\\lib\\socket.py\", line 833, in create_connection\n",
            "    sock.connect(sa)\n",
            "KeyboardInterrupt: \n"
          ]
        }
      ],
      "source": [
        "ind = 0\n",
        "while ind < 2:\n",
        "    soup = crawler(f\"https://www.amazon.com/s?k={df['title'][ind]}\")\n",
        "\n",
        "    if soup.text.replace(\"\\n\", \"\").strip(\" \") == \"Page Not Found\":\n",
        "        all_rank.append(\"_\")\n",
        "        other_info.append(\"_\")\n",
        "        origin_price.append(\"_\")\n",
        "        print(\"[\", ind, \"]\", \"Page Not Found!!!!!!!\")\n",
        "        ind = ind + 1\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        ul = soup.find_all(\"ul\", class_=\"a-unordered-list a-nostyle a-vertical a-spacing-none detail-bullet-list\")\n",
        "        rank_str = ul[1].find(\"span\", class_=\"a-list-item\").text\n",
        "        rank_str = rank_str.split(\" in Books (\")[0].strip(\"  Best Sellers Rank:  \")\n",
        "        all_rank.append(rank_str)\n",
        "\n",
        "        detail = soup.find(\"ul\", class_=\"a-unordered-list a-nostyle a-vertical a-spacing-none detail-bullet-list\").text\n",
        "        detail = detail.replace(\n",
        "            \"\\n                                    \\u200f\\n                                        :\\n                                    \\u200e\\n                                 \", \":\"\n",
        "        )\n",
        "        other_info.append(detail)\n",
        "\n",
        "    except IndexError:\n",
        "        try:\n",
        "            ul = soup.find(\"table\", class_=\"a-keyvalue a-vertical-stripes a-span6\")\n",
        "            rank_str = ul.find_all(\"tr\")[-1].find_all(\"span\")[1].text.split(\" in\", 1)[0]\n",
        "            all_rank.append(rank_str)\n",
        "\n",
        "            detail = ul.text\n",
        "            other_info.append(detail)\n",
        "\n",
        "        except AttributeError:\n",
        "            try:\n",
        "                ul = soup.find_all(\"table\", class_=\"a-keyvalue prodDetTable\")[1]\n",
        "                rank_str = ul.find_all(\"tr\")[-2].find_all(\"span\")[1].text.split(\" in\", 1)[0]\n",
        "                all_rank.append(rank_str)\n",
        "\n",
        "                detail = ul.text\n",
        "                other_info.append(detail)\n",
        "\n",
        "            except IndexError:\n",
        "                ind = ind\n",
        "                continue\n",
        "\n",
        "    except AttributeError:\n",
        "        try:\n",
        "            all_rank.append(\"_\")\n",
        "            other_info.append(\"_\")\n",
        "            origin_price.append(\"_\")\n",
        "            print(\"[\", ind, \"]\", \"detail only has consumer review???????\")\n",
        "            ind = ind + 1\n",
        "            continue\n",
        "        except AttributeError:\n",
        "            ind = ind\n",
        "            continue\n",
        "\n",
        "    try:\n",
        "        p = soup.find(\"div\", class_=\"a-section a-spacing-none a-text-right\")\n",
        "        p = p.find(\"span\", class_=\"a-color-secondary a-text-strike\")\n",
        "        origin_price.append(p.text)\n",
        "    except AttributeError:\n",
        "        origin_price.append(df.price[ind])\n",
        "\n",
        "    print(\"[\", ind, \"]\", df.title[ind])\n",
        "    ind = ind + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Best_Seller_other_info = pd.DataFrame(\n",
        "    {'all_rank':all_rank,\n",
        "     'origin_price':origin_price,\n",
        "     'other_info':other_info})\n",
        "Best_Seller_other_info.to_csv('Best_Seller_other_info_3500_3749.csv',index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "9R3wn-Rb7hpe",
        "4BiJna1c9_w0",
        "t1MI8FhZltE9"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
