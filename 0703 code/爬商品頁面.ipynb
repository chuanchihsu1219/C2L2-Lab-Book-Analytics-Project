{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup chrome options\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "chrome_options.add_argument(\"--disable-infobars\")\n",
    "chrome_options.add_argument(\"--disable-extensions\")\n",
    "chrome_options.add_argument(\"--disable-gpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'BestSeller_3dep.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 讀檔案\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBestSeller_3dep.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 把rank轉數字\u001b[39;00m\n\u001b[0;32m      4\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mint\u001b[39m(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m\"\u001b[39m][ind]\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mindex]\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'BestSeller_3dep.csv'"
     ]
    }
   ],
   "source": [
    "# 讀檔案\n",
    "df = pd.read_csv(\"BestSeller_3dep.csv\")\n",
    "# 把rank轉數字\n",
    "df[\"rank\"] = [int(df[\"rank\"][ind].strip(\"#\")) for ind in df.index]\n",
    "# 刪去重複的書(同類別但不同format)\n",
    "df = df.drop_duplicates(subset=[\"title\", \"author\", \"department\"]).reset_index()\n",
    "# 排序\n",
    "df = df.sort_values([\"department\", \"rank\"], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 爬總排名function\n",
    "# 如果爬不到會以\"_\"標記\n",
    "def FIND_RANK():\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    if soup.text.replace(\"\\n\", \"\").strip(\" \") == \"Page Not Found\":\n",
    "        all_rank = \"_\"\n",
    "        # 出現這個表示該頁面不存在\n",
    "        print(\"[\", ind, \"]\", \"Page Not Found!!!!!!!\")\n",
    "\n",
    "    try:\n",
    "        ul = soup.find_all(\"ul\", class_=\"a-unordered-list a-nostyle a-vertical a-spacing-none detail-bullet-list\")\n",
    "        rank_str = ul[1].find(\"span\", class_=\"a-list-item\").text\n",
    "        rank_str = rank_str.split(\" in\", 1)[0].strip(\"  Best Sellers Rank:  \")\n",
    "        all_rank = rank_str\n",
    "\n",
    "    except IndexError:\n",
    "        try:\n",
    "            ul = soup.find(\"table\", class_=\"a-keyvalue a-vertical-stripes a-span6\")\n",
    "            rank_str = ul.find_all(\"tr\")[-1].find_all(\"span\")[1].text.split(\" in\", 1)[0]\n",
    "            all_rank = rank_str\n",
    "\n",
    "        except AttributeError:\n",
    "            try:\n",
    "                ul = soup.find_all(\"table\", class_=\"a-keyvalue prodDetTable\")[1]\n",
    "                rank_str = ul.find_all(\"tr\")[-2].find_all(\"span\")[1].text.split(\" in\", 1)[0]\n",
    "                all_rank = rank_str\n",
    "\n",
    "            except IndexError:\n",
    "                all_rank = \"_\"\n",
    "\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            all_rank = \"_\"\n",
    "            # 出現這個表示該商品欄位只有評價\n",
    "            print(\"[\", ind, \"]\", \"detail only has consumer review???????\")\n",
    "        except AttributeError:\n",
    "            all_rank = \"_\"\n",
    "\n",
    "    print(\"[\", ind, \"]\", df.title[ind])\n",
    "\n",
    "    return all_rank\n",
    "\n",
    "\n",
    "# 爬其他資訊\n",
    "def FIND_OTHER_INFO():\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    if soup.text.replace(\"\\n\", \"\").strip(\" \") == \"Page Not Found\":\n",
    "        other_info = \"_\"\n",
    "\n",
    "    try:\n",
    "        ul = soup.find_all(\"ul\", class_=\"a-unordered-list a-nostyle a-vertical a-spacing-none detail-bullet-list\")\n",
    "\n",
    "        detail = soup.find(\"ul\", class_=\"a-unordered-list a-nostyle a-vertical a-spacing-none detail-bullet-list\").text\n",
    "        detail = detail.replace(\n",
    "            \"\\n                                    \\u200f\\n                                        :\\n                                    \\u200e\\n                                 \", \":\"\n",
    "        )\n",
    "        other_info = detail\n",
    "\n",
    "    except IndexError:\n",
    "        try:\n",
    "            ul = soup.find(\"table\", class_=\"a-keyvalue a-vertical-stripes a-span6\")\n",
    "\n",
    "            detail = ul.text\n",
    "            other_info = detail\n",
    "\n",
    "        except AttributeError:\n",
    "            try:\n",
    "                ul = soup.find_all(\"table\", class_=\"a-keyvalue prodDetTable\")[1]\n",
    "\n",
    "                detail = ul.text\n",
    "                other_info = detail\n",
    "\n",
    "            except IndexError:\n",
    "                other_info = \"_\"\n",
    "\n",
    "    except AttributeError:\n",
    "        other_info = \"_\"\n",
    "\n",
    "    return other_info\n",
    "\n",
    "\n",
    "# 爬主要資訊\n",
    "def APPEND_LIST():\n",
    "\n",
    "    df_append = pd.DataFrame({})\n",
    "\n",
    "    # price\n",
    "    try:\n",
    "        p = soup.find(\"div\", class_=\"a-section a-spacing-none a-text-right\")\n",
    "        p = p.find(\"span\", class_=\"a-color-secondary a-text-strike\")\n",
    "        before_discount = p.text\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            p = soup.find(\"tr\", class_=\"celwidget print-list-price\")\n",
    "            before_discount = p.text\n",
    "        except:\n",
    "            try:\n",
    "                p = soup.find(\"span\", class_=\"aok-relative\").find(\"span\", class_=\"a-offscreen\")\n",
    "                before_discount = p.text\n",
    "            except:\n",
    "                before_discount = \"_\"\n",
    "\n",
    "    try:\n",
    "        a_button_inners = MMGridLayout.find_all(\"span\", class_=\"a-button-inner\")\n",
    "        a_button_inner = a_button_inners[block]\n",
    "        slot_price = a_button_inner.find(\"span\", class_=\"slot-price\")\n",
    "        new_price = slot_price.text.replace(\"\\n\", \"\").strip(\" \")\n",
    "    except:\n",
    "        a_button_inner = MMGridLayout.find(\"span\", class_=\"a-button-inner\")\n",
    "        slot_price = a_button_inner.find(\"span\", class_=\"slot-price\")\n",
    "        new_price = slot_price.text.replace(\"\\n\", \"\").strip(\" \")\n",
    "\n",
    "    try:\n",
    "        extraMessage = a_button_inner.find(\"span\", class_=\"slot-extraMessage\").text\n",
    "        new_price = new_price + extraMessage\n",
    "    except:\n",
    "        extraMessage = \"\"\n",
    "\n",
    "    df_append = pd.DataFrame(\n",
    "        {\n",
    "            \"all_rank_list\": [FIND_RANK()],\n",
    "            \"format\": [format_str_orign.casefold().capitalize()],\n",
    "            \"before_discount\": [before_discount],\n",
    "            \"new_price\": [new_price],\n",
    "            \"title\": [df.title[ind]],\n",
    "            \"scrape_time\": [datetime.now() + timedelta(hours=8)],\n",
    "            \"other_list\": [FIND_OTHER_INFO()],\n",
    "            \"department\": [df.department[ind]],\n",
    "            \"author\": [df.author[ind]],\n",
    "        }\n",
    "    )\n",
    "    return df_append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建空的資料夾\n",
    "Best_Seller_other_info = pd.DataFrame({\n",
    "   'all_rank_list': [],  #總排名\n",
    "   'format':[],          #書的類別(paperback、hardcover等)\n",
    "   'before_discount':[], #打折前價格(如果沒打折，會標記為\"_\")\n",
    "   'new_price':[],       #新價格\n",
    "   'title':[],           #書名\n",
    "   'scrape_time':[],     #爬取書名\n",
    "   'other_list':[],      #其他資訊\n",
    "   'department':[],      #類別\n",
    "   'author':[]})         #書名\n",
    "# 如果讀不到東西，會用這個存起來\n",
    "not_append = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 開啟selenium chrome driver\n",
    "##############記得要把語言改成英文，不然價格就不是美金\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=chrome_options)\n",
    "driver.get(\"https://www.amazon.com/ref=nav_logo?language=en_US\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第3層的時候才要先篩出要爬的類別\n",
    "\n",
    "#中間處理(如果要爬全部就用不到)\n",
    "\n",
    "# 讀取檔案，這個檔案是paperback爬取完總排名後檢視各類別書籍的總排名的狀況\n",
    "Paper_dep2 = pd.read_csv('Paper_dep2_agg.csv')\n",
    "\n",
    "choose_dep = []\n",
    "for ind in Paper_dep2.index:\n",
    "  # 篩選\n",
    "  if Paper_dep2.twen_larg[ind] <=10000:\n",
    "    choose_dep.append(Paper_dep2['department'][ind])\n",
    "\n",
    "choose_index = []\n",
    "for ind in df.index:\n",
    "  dep_list = df.department[ind].split(' | ')\n",
    "  dep_2 = dep_list[0] + ' | ' + dep_list[1]\n",
    "  if dep_2 in choose_dep:\n",
    "    choose_index.append(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果是篩選過書籍，就把df.index改成choose_index\n",
    "\n",
    "for ind in df.index: \n",
    "  # 將欲爬網站輸入selenium chrome driver\n",
    "  driver.get(df.book_url[ind])\n",
    "  i = 0\n",
    "  while True:\n",
    "\n",
    "\n",
    "      time.sleep(1)\n",
    "      # 將現在網頁內容裝進python的soup內\n",
    "      soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "      i = i+1\n",
    "      print(i, end = ' ')\n",
    "      # 錯誤頁面\n",
    "      refuse_request = ['Request was throttled. Please wait a moment and refresh the page',\n",
    "                        '      503 - Service Unavailable Error',\n",
    "                        \"Amazon.comEnter the characters you see belowSorry, we just need to make sure you're not a robot. For best results, please make sure your browser is accepting cookies.Type the characters you see in this image:Try different imageContinue shoppingConditions of UsePrivacy Policy          © 1996-2014, Amazon.com, Inc. or its affiliates          \"]\n",
    "      if soup.text.replace('\\n','') in refuse_request:\n",
    "        driver.refresh()\n",
    "        time.sleep(30*i)\n",
    "\n",
    "      else:\n",
    "        break\n",
    "\n",
    "  # 即使顯示Page Not Found，還是裝進資料，事後檢查\n",
    "  if soup.text \\\n",
    "         .replace('\\n','') \\\n",
    "         .strip(' ') == 'Page Not Found':\n",
    "    df_append = pd.DataFrame({\n",
    "   'all_rank_list': ['_'],\n",
    "   'format':[df.format[ind]],\n",
    "   'before_discount':['_'],\n",
    "   'new_price':[df.price[ind]],\n",
    "   'title':[df.title[ind]],\n",
    "   'scrape_time':[datetime.now() + timedelta(hours = 8)],\n",
    "   'other_list':['_'],\n",
    "   'department':[df.department[ind]],\n",
    "   'author':[df.author[ind]]})\n",
    "    Best_Seller_other_info = pd.concat([Best_Seller_other_info, df_append],ignore_index=True)\n",
    "\n",
    "  # 爬取商品頁面右上角框框\n",
    "  MMGridLayout = soup.find('div',class_='a-section a-spacing-none MMGridLayout')\n",
    "  price_box = str(MMGridLayout).count('a-button-inner')\n",
    "  if price_box > 1:\n",
    "    \n",
    "    for block in range(price_box):\n",
    "      soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "      MMGridLayout = soup.find('div',class_='a-section a-spacing-none MMGridLayout')\n",
    "      try:\n",
    "        a_button_inner = MMGridLayout.find_all('span',class_='a-button-inner')[block]\n",
    "      except:\n",
    "        try:\n",
    "          time.sleep(5)\n",
    "          a_button_inner = MMGridLayout.find_all('span',class_='a-button-inner')[block]\n",
    "        except AttributeError:\n",
    "          not_append.append(f'{df.title[ind]}')\n",
    "          driver.back()\n",
    "          time.sleep(1)\n",
    "          continue\n",
    "      format_str = a_button_inner.find('span',class_='slot-title') \\\n",
    "                                  .text \\\n",
    "                                  .replace('\\n','') \\\n",
    "                                  .strip(' ') \\\n",
    "                                  .upper() \\\n",
    "                                  .replace('-','_') \\\n",
    "                                  .replace(' ','_') \\\n",
    "                                  .replace('\\xa0','')\n",
    "      try:\n",
    "        format_str = format_str.split('___')[0]\n",
    "      except:\n",
    "        format_str = format_str\n",
    "\n",
    "      format_str_orign = format_str\n",
    "\n",
    "      # selenium需要python這邊的字串和HTML格式相符才會點進網頁\n",
    "      paperback = ['PERFECT_PAPERBACK', 'PAMPHLET','UNBOUND','PAPERBACK_BUNKO']\n",
    "      if format_str in paperback:\n",
    "        format_str = 'PAPERBACK'\n",
    "\n",
    "      hardcover = ['LIBRARY_BINDING', 'LEATHER_BOUND', 'PRINTED_ACCESS_CODE','IMITATION_LEATHER','SCHOOL_&_LIBRARY_BINDING','PRODUCT_BUNDLE',\n",
    "                   'BONDED_LEATHER','VINYL_BOUND','HARDCOVER_SPIRAL','TURTLEBACK']\n",
    "      if format_str in hardcover:\n",
    "        format_str = \"HARDCOVER\"\n",
    "\n",
    "      if format_str == 'AUDIOBOOK':\n",
    "        format_str = 'AUDIO_DOWNLOAD'\n",
    "\n",
    "      audiobook = ['AUDIO_CD','MP3_CD','PRELOADED_DIGITAL_AUDIO_PLAYER','AUDIO,_CASSETTE','MP3_CD_LIBRARY_BINDING']\n",
    "      if format_str in audiobook:\n",
    "        format_str = 'AUDIOBOOK'\n",
    "\n",
    "      kindle = ['KINDLE_EDITION_WITH_AUDIO/VIDEO','ETEXTBOOK']\n",
    "      if format_str in kindle:\n",
    "        format_str = 'KINDLE'\n",
    "\n",
    "      if format_str == 'LOOSE_LEAF':\n",
    "        format_str = 'LOOSELEAF'\n",
    "\n",
    "      other_format = ['BOARD_BOOK','FLEXIBOUND','MULTIMEDIA_CD','MAGAZINE','SHEET_MUSIC','CARDS','COMICS','CALENDAR','POCKET_BOOK','DIGITAL','GAME','MAP',\n",
    "                      'WALL_CHART','BOOK_SUPPLEMENT','TOY','BATH_BOOK','POCKET_BOOK','TEXTBOOK_BINDING','WALL_CHART','PLASTIC_COMB']\n",
    "      if format_str in other_format:\n",
    "        format_str = 'OTHER'\n",
    "\n",
    "\n",
    "      # 點進該書之各個format之商品頁面\n",
    "      try:\n",
    "        driver.find_element(By.ID, f'tmm-grid-swatch-{format_str}') \\\n",
    "              .click()\n",
    "      except:\n",
    "        not_append.append(f'{df.title[ind]}: {format_str}')\n",
    "        continue\n",
    "\n",
    "      time.sleep(1)\n",
    "      soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "      if soup.text.replace('\\n','') in refuse_request:\n",
    "        i = 1\n",
    "        while True:\n",
    "          print(i, end = ' ')\n",
    "          driver.refresh()\n",
    "          time.sleep(1+(3*i))\n",
    "          soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "          i = i + 1\n",
    "          if soup.text.replace('\\n','') not in refuse_request:\n",
    "            break\n",
    "\n",
    "\n",
    "      df_append  = APPEND_LIST()\n",
    "      Best_Seller_other_info = pd.concat([Best_Seller_other_info, df_append],ignore_index=True)\n",
    "\n",
    "  else:\n",
    "    # 如果只有一種類別\n",
    "    try:\n",
    "      a_button_inner = MMGridLayout.find('span',class_='a-button-inner')\n",
    "      format_str = a_button_inner.find('span',class_='slot-title') \\\n",
    "                                  .text \\\n",
    "                                  .replace('\\n','') \\\n",
    "                                  .strip(' ') \\\n",
    "                                  .upper() \\\n",
    "                                  .replace('-','_') \\\n",
    "                                  .replace(' ','_') \\\n",
    "                                  .replace('\\xa0','')\n",
    "      try:\n",
    "        format_str = format_str.split('___')[0]\n",
    "      except:\n",
    "        format_str = format_str\n",
    "\n",
    "      format_str_orign = format_str\n",
    "      df_append  = APPEND_LIST()\n",
    "      Best_Seller_other_info = pd.concat([Best_Seller_other_info, df_append],ignore_index=True)\n",
    "\n",
    "    # 商品頁面右上角沒有框框的時候(不另外寫function)\n",
    "    except AttributeError:\n",
    "      \n",
    "      try:\n",
    "        before_discount = soup.find('span',class_='a-price a-text-price') \\\n",
    "                                  .find('span',class_='a-offscreen') \\\n",
    "                                  .text\n",
    "      except AttributeError:\n",
    "        before_discount = '_'\n",
    "\n",
    "      try:\n",
    "        new_price = soup.find('span',class_='a-price aok-align-center') \\\n",
    "                            .find('span',class_='a-offscreen') \\\n",
    "                            .text\n",
    "      except AttributeError:\n",
    "        try:\n",
    "          new_price = soup.find('span',class_='a-price a-text-normal aok-align-center reinventPriceAccordionT2') \\\n",
    "                          .find('span',class_='a-offscreen') \\\n",
    "                          .text\n",
    "        except AttributeError:\n",
    "          new_price = df.price[ind]\n",
    "\n",
    "      try:\n",
    "        extraMessage = a_button_inner.find('span',class_='slot-extraMessage') \\\n",
    "                                 .text\n",
    "        new_price = new_price + extraMessage\n",
    "      except:\n",
    "        extraMessage = ''\n",
    "\n",
    "      df_append = pd.DataFrame({\n",
    "              'all_rank_list': [FIND_RANK()],\n",
    "              'format':[df.format[ind]],\n",
    "              'before_discount':[before_discount],\n",
    "              'new_price':[new_price],\n",
    "              'title':[df.title[ind]],\n",
    "              'scrape_time':[datetime.now() + timedelta(hours = 8)],\n",
    "              'other_list':[FIND_OTHER_INFO()],\n",
    "              'department':[df.department[ind]],\n",
    "              'author':[df.author[ind]]})\n",
    "      Best_Seller_other_info = pd.concat([Best_Seller_other_info, df_append],ignore_index=True)\n",
    "\n",
    "  print('[',ind,']', df.title[ind])\n",
    "\n",
    "# 關掉selenium chrome driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#存檔\n",
    "Best_Seller_other_info.to_csv('AmazonBS_other_info_2dep.csv',index=False)\n",
    "\n",
    "# 存沒爬到的東西\n",
    "with open(\"not_append.txt\",'w') as f:\n",
    "    for row in not_append:\n",
    "        f.write(\"%s\\n\" % row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#檢查沒爬到的書\n",
    "for ind in Best_Seller_other_info.index:\n",
    "    if Best_Seller_other_info['all_rank_list']=='_':\n",
    "        print(ind, Best_Seller_other_info['title'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
