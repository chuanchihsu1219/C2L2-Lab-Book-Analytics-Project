{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup chrome options\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "chrome_options.add_argument(\"--disable-infobars\")\n",
    "chrome_options.add_argument(\"--disable-extensions\")\n",
    "chrome_options.add_argument(\"--disable-gpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用來把資料存在各個list裡的function，之後會建成dataframe\n",
    "def best_seller_function(gridItemRoot, department_list, department_str, rank, title, book_url, author, price, time_scrape):\n",
    "    # department\n",
    "    department_list.append(department_str)\n",
    "\n",
    "    # rank\n",
    "    rank.append(gridItemRoot.find(\"span\", class_=\"zg-bdg-text\").text)\n",
    "\n",
    "    # title\n",
    "    try:\n",
    "        title.append(gridItemRoot.find(\"div\", class_=\"_cDEzb_p13n-sc-css-line-clamp-2_EWgCb\").text)\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            title.append(gridItemRoot.find(\"div\", class_=\"_cDEzb_p13n-sc-css-line-clamp-3_g3dy1\").text)\n",
    "        except AttributeError:\n",
    "            try:\n",
    "                title.append(gridItemRoot.find(\"div\", class_=\"_cDEzb_p13n-sc-css-line-clamp-4_2q2cc\").text)\n",
    "            except AttributeError:\n",
    "                try:\n",
    "                    title.append(gridItemRoot.find_all(\"div\", class_=\"_cDEzb_p13n-sc-css-line-clamp-1_1Fn1y\")[0].text)\n",
    "                except IndexError:\n",
    "                    title.append(gridItemRoot.find(\"div\", class_=\"_cDEzb_p13n-sc-css-line-clamp-5_2l-dX\").text)\n",
    "\n",
    "    # book url\n",
    "    book_url.append(f\"https://www.amazon.com{gridItemRoot.find_all('a',class_='a-link-normal')[1].get('href')}\")\n",
    "\n",
    "    # author\n",
    "    try:\n",
    "        author.append(gridItemRoot.find_all(\"div\", class_=\"_cDEzb_p13n-sc-css-line-clamp-1_1Fn1y\")[1].text)\n",
    "    except IndexError:\n",
    "        try:\n",
    "            author.append(gridItemRoot.find(\"div\", class_=\"_cDEzb_p13n-sc-css-line-clamp-1_1Fn1y\").text)\n",
    "        # 如果沒有author，就以\"_\"標記\n",
    "        except AttributeError:\n",
    "            author.append(\"_\")\n",
    "\n",
    "    # format\n",
    "    try:\n",
    "        format.append(gridItemRoot.find(\"span\", class_=\"a-size-small a-color-secondary a-text-normal\").text)\n",
    "    # 如果沒有format，就以\"_\"標記\n",
    "    except AttributeError:\n",
    "        format.append(\"_\")\n",
    "\n",
    "    # price\n",
    "    try:\n",
    "        price.append(gridItemRoot.find(\"span\", class_=\"_cDEzb_p13n-sc-price_3mJ9Z\").text)\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            a_color_secondary = gridItemRoot.find_all(\"span\", class_=\"a-color-secondary\")[-1].text\n",
    "\n",
    "            # 由於a-color-secondary可能會爬到別的東西，辨別價格方法是有沒有$\n",
    "            if a_color_secondary.count(\"$\") == 1:\n",
    "                price.append(a_color_secondary)\n",
    "            else:\n",
    "                price.append(\"_\")\n",
    "        except IndexError:\n",
    "            price.append(\"_\")\n",
    "\n",
    "    # scrape time\n",
    "    time_scrape.append(datetime.now() + timedelta(hours=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input\n",
    "\n",
    "url = []\n",
    "# 讀取要爬的類別總榜前100\n",
    "with open('url.txt','r') as f:\n",
    "    for row in f:\n",
    "      if row != '\\n':\n",
    "        url.append(row.rstrip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建空的list\n",
    "# url_conti: 存下一層類別的網址\n",
    "# departments: 存所屬類別\n",
    "# rank: 存類別排名\n",
    "# title: 存書名\n",
    "# book_url: 存商品頁面網址\n",
    "# format: 存書的樣式(如paperback、hardcover、kindle等)\n",
    "# price: 存價格\n",
    "# time_scrape: 存爬取時間\n",
    "url_conti, departments, rank, title, book_url, author, format, price, time_scrape =[],[],[],[],[],[],[],[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 開啟selenium chrome driver\n",
    "##############記得要把語言改成英文，不然價格就不是美金\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()),\n",
    "                          options=chrome_options)\n",
    "driver.get('https://www.amazon.com/ref=nav_logo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 斷掉的話要改index\n",
    "for row in url[:]:\n",
    "    # 將欲爬網站輸入selenium chrome driver\n",
    "    driver.get(row)\n",
    "    # 爬Amazon慣例會先重新載入一次，大幅減少錯誤頁面機率\n",
    "    driver.refresh()\n",
    "    i = 0\n",
    "    while True:\n",
    "        # 要selemium向下滾動的code\n",
    "        time.sleep(1)\n",
    "        driver.execute_script(\"window.scrollBy(0, 5000);\")\n",
    "        time.sleep(1)\n",
    "        driver.execute_script(\"window.scrollBy(0, 3000);\")\n",
    "        time.sleep(2)\n",
    "        driver.execute_script(\"window.scrollBy(0, 2500);\")\n",
    "        time.sleep(6)\n",
    "        driver.execute_script(\"window.scrollBy(0, 3000);\")\n",
    "        time.sleep(2)\n",
    "        driver.execute_script(\"window.scrollBy(0, 2560);\")\n",
    "        time.sleep(4)\n",
    "        # 將現在網頁內容裝進python的soup內\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        i = i+1\n",
    "        print(i, end = ' ')\n",
    "        # 錯誤頁面\n",
    "        refuse_request = ['Request was throttled. Please wait a moment and refresh the page',\n",
    "                          '      503 - Service Unavailable Error']\n",
    "        if soup.text.replace('\\n','').count(\"Sorry, we just need to make sure you're not a robot.\") == 1:\n",
    "          driver.refresh()\n",
    "          time.sleep(30*i)\n",
    "\n",
    "        if soup.text.replace('\\n','').count(\"500 - An error occurred\") == 1:\n",
    "          driver.refresh()\n",
    "          time.sleep(30*i)\n",
    "        \n",
    "        if soup.text.replace('\\n','') in refuse_request:\n",
    "          driver.refresh()\n",
    "          time.sleep(30*i)\n",
    "\n",
    "        # 如果沒有錯誤頁面，就只有1次的while迴圈\n",
    "        else:\n",
    "          break\n",
    "    \n",
    "    #找出左側的類別欄\n",
    "    div = soup.find_all('div', class_='_p13n-zg-nav-tree-all_style_zg-browse-group__88fbz')\n",
    "    group = div[-1].find_all('div', class_='_p13n-zg-nav-tree-all_style_zg-browse-item__1rdKf _p13n-zg-nav-tree-all_style_zg-browse-height-large__1z5B8')\n",
    "    non_sub_department_str = '<span class=\"_p13n-zg-nav-tree-all_style_zg-selected__1SfhQ\">'\n",
    "\n",
    "    # 爬類別名稱\n",
    "    high_department = ''\n",
    "\n",
    "    # 爬較高順位之類別名稱\n",
    "    try:\n",
    "      _p13n = div[0].find_all('div',class_='_p13n-zg-nav-tree-all_style_zg-browse-item__1rdKf _p13n-zg-nav-tree-all_style_zg-browse-height-large__1z5B8 _p13n-zg-nav-tree-all_style_zg-browse-up__XTlqh')\n",
    "      for p13n in _p13n:\n",
    "        # 以|隔開\n",
    "        high_department = high_department + p13n.find('a').text + ' | '\n",
    "\n",
    "    except AttributeError:\n",
    "      _p13n = div[0].find('div',class_='_p13n-zg-nav-tree-all_style_zg-browse-item__1rdKf _p13n-zg-nav-tree-all_style_zg-browse-height-large__1z5B8 _p13n-zg-nav-tree-all_style_zg-browse-up__XTlqh')\n",
    "      high_department = high_department + _p13n.find('a').text + ' | '\n",
    "\n",
    "    # 爬較低順位之類別\n",
    "    high_department = high_department + div[-2].find('div',class_='_p13n-zg-nav-tree-all_style_zg-browse-item__1rdKf _p13n-zg-nav-tree-all_style_zg-browse-height-large__1z5B8').text\n",
    "    try:\n",
    "      department = div[-1].find('span',class_='_p13n-zg-nav-tree-all_style_zg-selected__1SfhQ').text\n",
    "      high_department = high_department + ' | '+ department\n",
    "      high_department = high_department.replace('Books | ','',1)\n",
    "    except AttributeError:\n",
    "      high_department = high_department.replace('Books | ','',1)\n",
    "\n",
    "    # 爬想要的資訊\n",
    "    gridRow = soup.find_all('div',class_='a-column a-span12 a-text-center _cDEzb_grid-column_2hIsc')\n",
    "    for gridItemRoot in gridRow:\n",
    "      if gridItemRoot.text == 'This item is no longer available':\n",
    "            continue\n",
    "      best_seller_function(gridItemRoot, departments, high_department, rank, title, book_url, author, price, time_scrape)\n",
    "\n",
    "    #爬第二頁(50-100名)\n",
    "    try:\n",
    "      li = soup.find('li',class_='a-normal').find('a').get('href')\n",
    "      url_end_2 = f\"https://www.amazon.com{li}\"\n",
    "      driver.get(url_end_2)\n",
    "      driver.refresh()\n",
    "      i = 0\n",
    "      while True:\n",
    "\n",
    "            time.sleep(1)\n",
    "            driver.execute_script(\"window.scrollBy(0, 5000);\")\n",
    "            time.sleep(1)\n",
    "            driver.execute_script(\"window.scrollBy(0, 3000);\")\n",
    "            time.sleep(2)\n",
    "            driver.execute_script(\"window.scrollBy(0, 2500);\")\n",
    "            time.sleep(6)\n",
    "            driver.execute_script(\"window.scrollBy(0, 3000);\")\n",
    "            time.sleep(2)\n",
    "            driver.execute_script(\"window.scrollBy(0, 2560);\")\n",
    "            time.sleep(4)\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            i = i+1\n",
    "            print(i, end = ' ')\n",
    "            refuse_request = ['Request was throttled. Please wait a moment and refresh the page',\n",
    "                              '      503 - Service Unavailable Error']\n",
    "            if soup.text.replace('\\n','').count(\"Sorry, we just need to make sure you're not a robot.\") == 1:\n",
    "              driver.refresh()\n",
    "              time.sleep(30*i)\n",
    "            \n",
    "            if soup.text.replace('\\n','') in refuse_request:\n",
    "              driver.refresh()\n",
    "              time.sleep(30*i)\n",
    "\n",
    "            else:\n",
    "              break\n",
    "      gridRow = soup.find_all('div',class_='a-column a-span12 a-text-center _cDEzb_grid-column_2hIsc')\n",
    "      for gridItemRoot in gridRow:\n",
    "        if gridItemRoot.text == 'This item is no longer available':\n",
    "              continue\n",
    "        best_seller_function(gridItemRoot, departments, high_department, rank, title, book_url, author, price, time_scrape)\n",
    "    except AttributeError:\n",
    "      url_end_2 = '_'\n",
    "\n",
    "    # 如果有爬到，就會印出這些字串\n",
    "    print('---[',url.index(row),']', high_department, 'appends best sellers url')\n",
    "\n",
    "    # 爬下一層類別的網址\n",
    "    for treeitem in group:\n",
    "      try:\n",
    "        url_conti.append(f'http://www.amazon.com{treeitem.find(\"a\").get(\"href\")}')\n",
    "      except AttributeError:\n",
    "        continue\n",
    "    print(url.index(row),'---new')\n",
    "\n",
    "# 爬完關掉selenium chrome\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 檢查資料長度一樣\n",
    "print(len(rank), len(title), len(book_url), len(author), len(format), len(price), len(time_scrape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output\n",
    "\n",
    "# 裝成df並儲存\n",
    "Best_Sellers_df = pd.DataFrame({\n",
    "    'department':departments,\n",
    "    'rank': rank,\n",
    "    'title':title,\n",
    "    'book_url':book_url,\n",
    "    'author':author,\n",
    "    'format':format,\n",
    "    'price':price,\n",
    "    'scrape_time':time_scrape})\n",
    "\n",
    "# 檢查是否爬重複\n",
    "Best_Sellers_df = Best_Sellers_df.drop_duplicates(subset=['department','title','book_url','author','format'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 存檔\n",
    "Best_Sellers_df.to_csv('Best_Sellers_1dep.csv',index=False)\n",
    "\n",
    "# 存下一層類別排名網址\n",
    "with open(\"url_2.txt\",'w') as f:\n",
    "    for row in url_conti:\n",
    "        f.write(\"%s\\n\" % row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 檢查是否漏抓第50名和第100名資料\n",
    "Best_Sellers_df.drop_duplicates(subset = ['department'])['department']\n",
    "df_rank50 = list(Best_Sellers_df[Best_Sellers_df['rank'] == '#50'].drop_duplicates(subset = ['department'])['department'])\n",
    "df_rank100 = list(Best_Sellers_df[Best_Sellers_df['rank'] == '#100'].drop_duplicates(subset = ['department'])['department'])\n",
    "\n",
    "find_not_append_dep = []\n",
    "for x in list(Best_Sellers_df.drop_duplicates(subset = ['department'])['department']):\n",
    "    if x not in df_rank50:\n",
    "        find_not_append_dep.append(x)\n",
    "    if x not in df_rank100:\n",
    "        find_not_append_dep.append(x)\n",
    "\n",
    "find_not_append_dep = [x.split(' | ')[-1].replace(' ','-') for x in find_not_append_dep]\n",
    "find_not_append_dep"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
